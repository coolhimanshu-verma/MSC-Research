{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "clickbait_text_simple_bert.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "hvxuNyxGJJQS",
        "apwnNkDIMfI3",
        "QxCPi9hLMy8T"
      ],
      "mount_file_id": "1YAqlTOZ1DuRR64WoGpLTz42UUCqbitiu",
      "authorship_tag": "ABX9TyOTgwsqZzZG3WFPCbnYRR3+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahul94jh/MSC-Research/blob/main/clickbait_text_simple_bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvxuNyxGJJQS"
      },
      "source": [
        "#Imports & Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_9epIi5LEMy"
      },
      "source": [
        "!pip install -q tensorflow-text\n",
        "!pip install -q tf-models-official"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sUnti8PIuTZ"
      },
      "source": [
        "import os, sys, math\n",
        "import numpy as np\n",
        "import random\n",
        "import pandas as pd\n",
        "import matplotlib as mpl\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "from tensorflow import keras\n",
        "from official.nlp import optimization  # to create AdamW optmizer\n",
        "AUTO = tf.data.experimental.AUTOTUNE # used in tf.data.Dataset API\n",
        "\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "\n",
        "import sys\n",
        "\n",
        "#Import custom script\n",
        "sys.path.append('/content/drive/MyDrive/Colab Notebooks/clcikbait_detection/scripts')\n",
        "from tf_dataset_helpers import read_tfrec_data\n",
        "import model_helpers as mh\n",
        "import visualization_helpers as vh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNVqH7r_JQIA"
      },
      "source": [
        "#Configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jb6cexTEJHnA"
      },
      "source": [
        "PATH_OUTPUT = '/content/drive/MyDrive/Colab Notebooks/clcikbait_detection/dataset/tfrec/tfrec_data/'\n",
        "\n",
        "TARGET_SIZE = [180, 180]\n",
        "CLASSES = ['nonclickbaits', 'clickbaits'] \n",
        "BATCH_SIZE = 32  \n",
        "VALIDATION_SPLIT = 0.3\n",
        "TESTING_SPLIT = 0.5\n",
        "WIDTH = 180\n",
        "HEIGHT = 180"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNE-ZarzJU3M",
        "outputId": "0af2855b-7795-436e-c606-c0a012b32d5e"
      },
      "source": [
        "#instantiate read_data utility\n",
        "read_data = read_tfrec_data(PATH_OUTPUT,TARGET_SIZE=TARGET_SIZE, MODE=1)\n",
        "\n",
        "# splitting data files between training, validation and test\n",
        "filenames, training_filenames, validation_filenames, testing_filenames = read_data.get_tfrec_files()\n",
        "\n",
        "validation_steps = int(15572 // len(filenames) * len(validation_filenames)) // BATCH_SIZE\n",
        "steps_per_epoch = int(15572 // len(filenames) * len(training_filenames)) // BATCH_SIZE\n",
        "print(\"With a batch size of {}, there will be {} batches per training epoch and {} batch(es) per validation run.\".format(BATCH_SIZE, steps_per_epoch, validation_steps))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pattern matches 16 data files. Splitting dataset into 12 training files , 2 validation files and 2 test files\n",
            "With a batch size of 32, there will be 364 batches per training epoch and 60 batch(es) per validation run.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vk9G-0bYUfXz"
      },
      "source": [
        "def read_tfrecord(example):\n",
        "    features = {\n",
        "        \"image\": tf.io.FixedLenFeature([], tf.string),  # tf.string = bytestring (not text string)\n",
        "        \"class\": tf.io.FixedLenFeature([], tf.int64),   # shape [] means scalar\n",
        "        \"text\": tf.io.FixedLenFeature([], tf.string),\n",
        "        \n",
        "        # additional (not very useful) fields to demonstrate TFRecord writing/reading of different types of data\n",
        "        \"label\":         tf.io.FixedLenFeature([], tf.string),  # one bytestring\n",
        "        \"size\":          tf.io.FixedLenFeature([2], tf.int64)  # two integers\n",
        "    }\n",
        "    # decode the TFRecord\n",
        "    example = tf.io.parse_single_example(example, features)\n",
        "    \n",
        "    # FixedLenFeature fields are now ready to use: exmple['size']\n",
        "    # VarLenFeature fields require additional sparse_to_dense decoding\n",
        "    \n",
        "    image = tf.image.decode_jpeg(example['image'], channels=3)\n",
        "    image = tf.reshape(image, [*TARGET_SIZE, 3])\n",
        "    \n",
        "    class_num = example['class']\n",
        "    text = example['text']\n",
        "    label  = example['label']\n",
        "    height = example['size'][0]\n",
        "    width  = example['size'][1]\n",
        "    return image, text, class_num, label, height, width\n",
        "\n",
        "def load_dataset(filenames):\n",
        "  # read from TFRecords. For optimal performance, read from multiple\n",
        "  # TFRecord files at once and set the option experimental_deterministic = False\n",
        "  # to allow order-altering optimizations.\n",
        "\n",
        "  option_no_order = tf.data.Options()\n",
        "  option_no_order.experimental_deterministic = False\n",
        "\n",
        "  dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO)\n",
        "  dataset = dataset.with_options(option_no_order)\n",
        "  dataset = dataset.map(read_tfrecord, num_parallel_calls=AUTO)\n",
        "  dataset = dataset.map(lambda image, text, class_num, label, height, width: (text, class_num))\n",
        "  return dataset\n",
        "\n",
        "def get_batched_dataset(filenames, train=False):\n",
        "  dataset = load_dataset(filenames)\n",
        "  dataset = dataset.cache() # This dataset fits in RAM\n",
        "  if train:\n",
        "    dataset = dataset.shuffle(10000)\n",
        "  dataset = dataset.batch(BATCH_SIZE)\n",
        "  dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n",
        "  # should shuffle too but this dataset was well shuffled on disk already\n",
        "  return dataset\n",
        "  # source: Dataset performance guide: https://www.tensorflow.org/guide/performance/datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mltauaEuJWjH"
      },
      "source": [
        "#Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpLcX_4WJXjP"
      },
      "source": [
        "# instantiate the datasets\n",
        "train_ds = get_batched_dataset(training_filenames, train=True)\n",
        "val_ds = get_batched_dataset(validation_filenames, train=False)\n",
        "test_ds = get_batched_dataset(testing_filenames, train=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Mj37JzYKLFj",
        "outputId": "dcca6177-1cb6-4611-caf3-2886f3b589d1"
      },
      "source": [
        "for text, class_num in train_ds.take(1):\n",
        "  for i in range(32):\n",
        "    print(f\"Sent {i} :- {text[i]}, Class={class_num[i]}, Label={CLASSES[class_num[i]]}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sent 0 :- b'private barbie collection our social media links my instagram mo vlogs my sisters instagram lanarose my snapchat mohamedoo my sisters snapchat lana rose facebook twitter my sister s youtube channel', Class=1, Label=clickbaits\n",
            "Sent 1 :- b'globalization and trade and poverty crash course economics what is globalization is globalization a good thing or not well i have an answer that may not surprise you it s complicated this week jacob and adriene will argue that globalization is in aggregate good free trade and globalization tend to provide an overall benefit and raises average incomes across the globe the downside is that it isn t good for every individual in the system in some countries manufacturing jobs move to places where labor costs are lower and some countries that receive the influx of jobs aren t prepared to deal with it from a regulatory standpoint anyway jacob and adriene can explain the whole thing to you in minutes crash course is on patreon you can support us directly by signing up at thanks to the following patrons for their generous monthly contributions that help keep crash course free for everyone forever mark eric kitchen jessica wode jeffrey thompson steve marshall moritz schmidt robert kunz tim curwick jason a saslow sr foxley elliot beter jacob ash christian jan schmid jirat christy huddleston daniel baulig chris peters anna ester volozh ian dundore caleb weeks want to find crash course elsewhere on the internet facebook twitter tumblr support crash course on patreon cc kids', Class=0, Label=nonclickbaits\n",
            "Sent 2 :- b'muhammad ali interview with barbara walters muhammad ali talks boxing faith and loss in interview with abc news barbara walters subscribe to abc news watch more on like abc news on facebook follow abc news on twitter good morning america s homepage', Class=0, Label=nonclickbaits\n",
            "Sent 3 :- b'travel tips and paper towns movie updates paper towns movie july th paper towns trailer soonish in which john finds himself in a stunning turn of events in an airport where he shares some travel tips and also discusses the movie adaptation of his book paper towns the maybe possible adaptation of looking for alaska and cookie monster teenvogue and fox are hosting a paper towns event in ny and there are tickets available more information here if you re interested subscribe to our newsletter and join the community at help transcribe videos john s twitter john s tumblr hank s twitter hank s tumblr', Class=0, Label=nonclickbaits\n",
            "Sent 4 :- b'haircut vs free haircut let s smash likes for that amazing haircut my clothing store subscribe contact follow me snapchat teeqofaze faze house adapt apex rain temperrr blaziken subscribe thanks for watching love you guys faze teeqo', Class=1, Label=clickbaits\n",
            "Sent 5 :- b'obey blaziken road to the perfect floater random leave a like comment if you enjoyed subscribe my twitter my twitch my instagram song rameses b asteroid', Class=1, Label=clickbaits\n",
            "Sent 6 :- b'how to fall asleep fast life hacks you need to know how to fall asleep fast and easily simple easy life hacks for sleep phones snacks and more today we have incredible life hacks that everyone should know some of these life hacks are also christmas related too watch the video to discover some brand new life hacks tricks that you can do to improve your life i hope you all enjoyed this life hacks video i ve never done anything life hack related so if you want more life hacks on the channel or maybe a video dedicated to a specific group of life hacks eg smartphone life hacks if thats what you want then leave a like on the video and also subscribe to the channel if you re new stay active for a follow follow me on twitter follow me on instagram add my snapchat morgzhudson yo guys first of all thank you so much for watching it would be great if you could leave a like rating as it motivates me to keep creating content for you all also if you are new then please hit that subscribe button to join teammorgz finally if you have any questions feedback or just general comments then be sure to leave it in the comment section below brand new apparel follow me on twitter stay active for a follow follow me on instagram stay active for a follow follow my apparel twitter follow my twitch add my snapchat morgzhudson stay active for a follow my gaming chair uk use morgz for a discount my gaming chair us use morgz for a discount cheap reliable games my po box all packages sent will be opened in a video morgz po box dronfield s dp united kingdom business enquiries stay awesome guys d sources', Class=1, Label=clickbaits\n",
            "Sent 7 :- b'bought another rolex thank you for stopping by the channel if you enjoyed join the bruh bruh family by clicking here d join the fun snapchat youngsimbahhh twitter instagram merch for business and bookings please email keep grindin my friends', Class=1, Label=clickbaits\n",
            "Sent 8 :- b'what is bitcoin and how does it work mashable explains it s hard to deny that bitcoin is changing the way we use money and our concept of how currency should work so what is bitcoin exactly credits photo of different currencies decentralized centralized illustration mashable composite istockphoto betamax nicoolay johnwoodcock retroimages aristotoo x patrick damiano blockchain courtesy of silicon angle blockchain info miner miner miner bitcoin stock video istock movie elements bitcoin stock photo bitcoin creation rate chart wikipedia bitcoin atm abc news bitcoin value graph blockchain info techknowledgy you can use from verizon like us on facebook follow us on twitter follow us on tumblr follow our instagram join our circle on google plus subscribe mashable is the leading independent news site for all things tech social media and internet culture like us on facebook follow us on twitter follow us on tumblr follow our instagram join our circle on google plus subscribe mashable is the leading independent news site for all things tech social media and internet culture', Class=0, Label=nonclickbaits\n",
            "Sent 9 :- b'denzel washington dramatically reads greeting cards denzel washington and jimmy take turns giving extremely dramatic readings of standard greeting cards subscribe now to the tonight show starring jimmy fallon watch the tonight show starring jimmy fallon weeknights c get more jimmy fallon follow jimmy like jimmy get more the tonight show starring jimmy fallon follow the tonight show like the tonight show the tonight show tumblr get more nbc nbc youtube like nbc follow nbc nbc tumblr nbc google the tonight show starring jimmy fallon features hilarious highlights from the show including comedy sketches music parodies celebrity interviews ridiculous games and of course jimmy s thank you notes and hashtags you ll also find behind the scenes videos and other great web exclusives denzel washington dramatically reads greeting cards', Class=0, Label=nonclickbaits\n",
            "Sent 10 :- b'crazy tomahawk trickshot w reaction leave a like if you enjoyed todays video be sure to subscribe if you re new for more uploads d twitter instagram my stream my faze shirt use code rug for off kontrol freeks i use the ultra use code rug for off scufs i prefer the hybrids d', Class=1, Label=clickbaits\n",
            "Sent 11 :- b'bill gates we can eradicate some of the world s worst diseases by bill gates believes that innovations in technology medicine and public health can better the health of the world s poor within the next years as our february guest editor he outlines some of his immediate goals to halve the number of children who die before age five reduce the number of mothers who die in childbirth by two thirds and eradicate infectious diseases like polio guinea work river blindness and elephantiasis subscribe check out our full video catalog visit our playlists like the verge on facebook follow on twitter follow on instagram read more', Class=0, Label=nonclickbaits\n",
            "Sent 12 :- b'a mei zing overwatch holiday update a mei zing overwatch winter wonderland holiday update opening overwatch holiday loot boxes winter wonderland skins emotes voice lines and more for the overwatch holiday event leave a like if you enjoyed subscribe to join the wolf pack and follow me twitter instagram facebook twitch my shirt store business inquires po box sssniperwolf po box peoria az my gaming chair use code sss for off your order from gt omega racing channel art by', Class=1, Label=clickbaits\n",
            "Sent 13 :- b'where to meet girls with similar interests where to meet girls or guys with similar interests as you i honestly recommend online dating comment below and tell me what you think or ask questions leave a like if you enjoyed or found this helpful follow me so you don t miss any videos or cool updates twitter twitch facebook instagram business inquires my shirt store my cosplay print store yes i ship everywhere and prints come signed and with an optional special message that you can request my energy drink use code sss for off your order from gamma my custom controller use code sss for off your order from imagine customs my gaming chair use code sss for off your order from gt omega racing channel art by', Class=1, Label=clickbaits\n",
            "Sent 14 :- b'dog goes hiking new video subscribe for daily vlogs follow me on twitter to stay updated when i post instagram facebook vine snapchat itslance fan mail po box hurffville rd deptford nj business email', Class=1, Label=clickbaits\n",
            "Sent 15 :- b'foreign john green books and the ultimate concern in which john green discusses a few of the foreign editions of his novels looking for alaska an abundance of katherines and paper towns all while discussing the idea of an ultimate concern including the question of whether and how it is possible to live by the utilitarian values advocated for by many nerdfighters and there is a brief mention of boobs here are a lot of links to nerdfightastic things shirts and stuff hank s music john s books hank s twitter hank s facebook hank s tumblr john s twitter john s facebook john s tumblr other channels crash course scishow gaming vidcon hank s channel truth or fail nerdfighteria a bunny', Class=0, Label=nonclickbaits\n",
            "Sent 16 :- b'milk in glue bottle prank she slapped me lmfao my mom s reaction was priceless i love doing these types of pranks on my mom because she cares so much for my health hit that like button if you laughed throughout the prank love you all subscribe for daily content official rug apparel add me on snapchat thefazerug follow me on my social media to stay connected twitter instagram facebook snapchat thefazerug add me to see how i live my daily life d po box address faze rug p o box san diego ca use code rug for discounts on these products where i get my background music if you read this far down the description i love you', Class=1, Label=clickbaits\n",
            "Sent 17 :- b'crazy toilet paper prank on faze rain got him back let s smash likes for this epic prank subscribe my twitter my instagram my twitch my snapchat blazikenfaze use code sloth for gamma jerky discounts off off always stay slothy', Class=1, Label=clickbaits\n",
            "Sent 18 :- b'faze house freestyle subscribe to become an official rugrat add me on snapchat thefazerug check out my official rug apparel greatest jerky ever twitter instagram new faze member tee song dutty moonshine takin it back where i get my background music if you read this far down the description i love you', Class=1, Label=clickbaits\n",
            "Sent 19 :- b'the best fan mail opening ever the best fan mail opening ever someone sent underwear leave a like if you enjoyed subscribe to join the wolf pack and follow me twitter instagram facebook twitch my shirt store business inquires po box sssniperwolf po box peoria az my gaming chair use code sss for off your order from gt omega racing channel art by', Class=1, Label=clickbaits\n",
            "Sent 20 :- b'mobile tricks what can you do with your phone at google we love mobile phones and use them for everything here s our day in the life with phones but we bet you can do something more interesting upload your best mobile phone tip or trick to', Class=0, Label=nonclickbaits\n",
            "Sent 21 :- b'obama meets lucy a million year old human ancestor mashable lucy the most complete skeleton of an early human ancestor yet discovered got the opportunity of a lifetime on monday when she was introduced to us president barack obama during his visit to ethiopia the skeleton whose formal name is al referring to several hundred pieces of million year old bone from a female australopithecus afarensis discovered in ethiopia s afar region met the president during a state dinner at ethiopia s national palace by the associated press like us on facebook follow us on twitter follow us on tumblr follow our instagram join our circle on google plus subscribe mashable is the leading independent news site for all things tech social media and internet culture', Class=0, Label=nonclickbaits\n",
            "Sent 22 :- b'largest robots that actually exist top biggest robots in the world subscribe to our channel for copyright matters please contact us at david our social media facebook twitter instagram for more videos and articles visit', Class=1, Label=clickbaits\n",
            "Sent 23 :- b'he bought it for dollars i really hope it isn t real lol hour ffa faze rain merch vlog channel follow my social media s twitter instagram facebook snapchat nordansnap livestream the faze house adapt apex teeqo temperrr blaziken use code rainn on music by as always keep it real', Class=1, Label=clickbaits\n",
            "Sent 24 :- b'how to make money fast in gta gta online this will be gta gta online in this will be gta gta online gameplay help me get to k follow me on twitter more gta here', Class=1, Label=clickbaits\n",
            "Sent 25 :- b'she s now a model turn on my post notifications so you dont miss a video yesterdays vlog subscribe for daily vlogs follow me on twitter to stay updated when i post instagram facebook vine snapchat itslance fan mail box so black horse pike blackwood nj business email', Class=1, Label=clickbaits\n",
            "Sent 26 :- b'what you wish would happen on the walking dead prepare for walking dead s finale by reliving your favorite scenes or at least the scenes that would have been your favorites see more like us on follow us on follow us on', Class=0, Label=nonclickbaits\n",
            "Sent 27 :- b'the inspirations of betony vernon get a peek inside the author of the boudoir bible betony vernon s personal life subscribe to thnkr follow thnkr on twitter like thnkr on facebook or check out our tumblr epiphany is a series that invites impassioned thought leaders across all disciplines to reveal the innovative the improbable and the unexpected of their worlds created and produced by radical media thnkr gives you extraordinary access to the people stories places and thinking that will change your mind the views expressed in this video only represent those of the participants they do not necessarily represent the views or endorsement of radical media llc or any other party involved in the production and distribution of thnkr', Class=0, Label=nonclickbaits\n",
            "Sent 28 :- b'christmas with pranksters everyone deserves a christmas morning thanks for sharing behind the scenes follow me here follow dennis here twitter romanatwood twitter dennisroady instagram romanatwood instagram dennisroady more pranks here smile more store thanks so much for watching please help us out by sharing with some friends love you guys', Class=1, Label=clickbaits\n",
            "Sent 29 :- b'year old picking up girls new t shirts fails extras reveals facebook twitter instagram follow jensen more videos w jensen kid smoking experiment balloon prank vlogs licensing media business inquiries brian at whatever dot com camera i use camera i use camera i use microphone i use', Class=0, Label=nonclickbaits\n",
            "Sent 30 :- b'wu tang s gza drops knowledge at bronx compass in this science genius sequel gza of the wu tang clan makes a surprise visit to the bronx compass science students and blows their minds as co creator of science genius a pilot program which uses hip hop culture to teach science gza spends the class period working one on one with the students to craft tight rhymes about darwin s theory of natural selection prodigies is a bi weekly series showcasing the youngest and brightest as they challenge themselves to reach new heights and the stories behind them created and produced by radical media thnkr gives you extraordinary access to the people stories places and thinking that will change your mind follow thnkr on twitter like us on facebook check out our pinterest subscribe', Class=0, Label=nonclickbaits\n",
            "Sent 31 :- b'ourmine read the description hey it s ourmine don t worry we are just testing your security please contact us for more information the biggest hack in youtube history', Class=0, Label=nonclickbaits\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apwnNkDIMfI3"
      },
      "source": [
        "#Loading BERT models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWRh8gHjMjs-",
        "outputId": "065da407-b123-4e5b-8ea6-28bdcef05627"
      },
      "source": [
        "bert_model_name = 'small_bert/bert_en_uncased_L-4_H-512_A-8'\n",
        "\n",
        "map_name_to_handle = {\n",
        "    'bert_en_uncased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3',\n",
        "    'bert_en_cased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/3',\n",
        "    'bert_multi_cased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-768_A-12/1',\n",
        "    'albert_en_base':\n",
        "        'https://tfhub.dev/tensorflow/albert_en_base/2',\n",
        "    'electra_small':\n",
        "        'https://tfhub.dev/google/electra_small/2',\n",
        "    'electra_base':\n",
        "        'https://tfhub.dev/google/electra_base/2',\n",
        "    'experts_pubmed':\n",
        "        'https://tfhub.dev/google/experts/bert/pubmed/2',\n",
        "    'experts_wiki_books':\n",
        "        'https://tfhub.dev/google/experts/bert/wiki_books/2',\n",
        "    'talking-heads_base':\n",
        "        'https://tfhub.dev/tensorflow/talkheads_ggelu_bert_en_base/1',\n",
        "}\n",
        "\n",
        "map_model_to_preprocess = {\n",
        "    'bert_en_uncased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'bert_en_cased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_cased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'bert_multi_cased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3',\n",
        "    'albert_en_base':\n",
        "        'https://tfhub.dev/tensorflow/albert_en_preprocess/3',\n",
        "    'electra_small':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'electra_base':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'experts_pubmed':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'experts_wiki_books':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'talking-heads_base':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "}\n",
        "\n",
        "tfhub_handle_encoder = map_name_to_handle[bert_model_name]\n",
        "tfhub_handle_preprocess = map_model_to_preprocess[bert_model_name]\n",
        "\n",
        "print(f'BERT model selected           : {tfhub_handle_encoder}')\n",
        "print(f'Preprocess model auto-selected: {tfhub_handle_preprocess}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BERT model selected           : https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n",
            "Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxCPi9hLMy8T"
      },
      "source": [
        "#The preprocessing model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rR9FME8NMz9n",
        "outputId": "e0dedb18-3aa2-4981-a45e-1aea849a3749"
      },
      "source": [
        "bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)\n",
        "text_test = ['Woha this is not good']\n",
        "text_preprocessed = bert_preprocess_model(text_test)\n",
        "\n",
        "print(f'Keys       : {list(text_preprocessed.keys())}')\n",
        "print(f'Shape      : {text_preprocessed[\"input_word_ids\"].shape}')\n",
        "print(f'Word Ids   : {text_preprocessed[\"input_word_ids\"][0, :12]}')\n",
        "print(f'Input Mask : {text_preprocessed[\"input_mask\"][0, :12]}')\n",
        "print(f'Type Ids   : {text_preprocessed[\"input_type_ids\"][0, :12]}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Keys       : ['input_word_ids', 'input_mask', 'input_type_ids']\n",
            "Shape      : (1, 128)\n",
            "Word Ids   : [  101 24185  3270  2023  2003  2025  2204   102     0     0     0     0]\n",
            "Input Mask : [1 1 1 1 1 1 1 1 0 0 0 0]\n",
            "Type Ids   : [0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SeUwiESePAeZ",
        "outputId": "670ec65e-aef7-47af-b440-aadb1ca76597"
      },
      "source": [
        "bert_model = hub.KerasLayer(tfhub_handle_encoder)\n",
        "bert_results = bert_model(text_preprocessed)\n",
        "\n",
        "print(f'Loaded BERT: {tfhub_handle_encoder}')\n",
        "print(f'Pooled Outputs Shape:{bert_results[\"pooled_output\"].shape}')\n",
        "print(f'Pooled Outputs Values:{bert_results[\"pooled_output\"][0, :12]}')\n",
        "print(f'Sequence Outputs Shape:{bert_results[\"sequence_output\"].shape}')\n",
        "print(f'Sequence Outputs Values:{bert_results[\"sequence_output\"][0, :12]}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded BERT: https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n",
            "Pooled Outputs Shape:(1, 512)\n",
            "Pooled Outputs Values:[ 0.7643849   0.927498    0.14012101  0.2874884  -0.34276435  0.99576205\n",
            "  0.9954885  -0.9888585  -0.209736   -0.9980544   0.2121798  -0.91461587]\n",
            "Sequence Outputs Shape:(1, 128, 512)\n",
            "Sequence Outputs Values:[[ 4.3141788e-01  3.6393815e-01  2.1100295e-01 ... -3.7322488e-01\n",
            "   2.9361397e-01  3.3429481e-02]\n",
            " [ 2.4446827e-01  6.4271438e-01  4.3196508e-01 ... -6.0575664e-01\n",
            "   1.0509470e+00 -9.2043179e-01]\n",
            " [ 9.8580718e-03  4.7295555e-01  1.4971516e-01 ...  9.3666583e-02\n",
            "   4.5378631e-01  6.5911072e-01]\n",
            " ...\n",
            " [ 4.0350115e-01  2.6286304e-02 -4.1952828e-01 ...  2.3472810e-01\n",
            "   7.7093351e-01  3.1780475e-01]\n",
            " [ 4.8367512e-01  2.4531884e-01 -2.6954496e-01 ...  4.2330563e-02\n",
            "   9.8433572e-01  2.5446779e-01]\n",
            " [ 4.1724241e-01  3.1108081e-01 -2.3493069e-01 ...  8.0616772e-04\n",
            "   8.4748960e-01  5.0131455e-03]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-mFT3BkQ-vk"
      },
      "source": [
        "#Define your model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJ4bSNzeRDjq"
      },
      "source": [
        "def build_classifier_model():\n",
        "  text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "  preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n",
        "  encoder_inputs = preprocessing_layer(text_input)\n",
        "  encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n",
        "  outputs = encoder(encoder_inputs)\n",
        "  net = outputs['pooled_output']\n",
        "  net = tf.keras.layers.Dropout(0.1)(net)\n",
        "  net = tf.keras.layers.Dense(1, activation=None, name='classifier')(net)\n",
        "  return tf.keras.Model(text_input, net)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdLterEjRWio"
      },
      "source": [
        "classifier_model = build_classifier_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U03HfimITxps",
        "outputId": "97726405-97fa-41c1-ed67-7cbe4c915731"
      },
      "source": [
        "classifier_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text (InputLayer)               [(None,)]            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "preprocessing (KerasLayer)      {'input_word_ids': ( 0           text[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "BERT_encoder (KerasLayer)       {'encoder_outputs':  28763649    preprocessing[0][0]              \n",
            "                                                                 preprocessing[0][1]              \n",
            "                                                                 preprocessing[0][2]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 512)          0           BERT_encoder[0][5]               \n",
            "__________________________________________________________________________________________________\n",
            "classifier (Dense)              (None, 1)            513         dropout_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 28,764,162\n",
            "Trainable params: 28,764,161\n",
            "Non-trainable params: 1\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IbIgEtTRxIt"
      },
      "source": [
        "#Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3050YlYdRyJu"
      },
      "source": [
        "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "metrics = tf.metrics.BinaryAccuracy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IpUZigYR1tB"
      },
      "source": [
        "epochs = 5\n",
        "num_train_steps = steps_per_epoch * epochs\n",
        "num_warmup_steps = int(0.1*num_train_steps)\n",
        "\n",
        "init_lr = 3e-5\n",
        "optimizer = optimization.create_optimizer(init_lr=init_lr,\n",
        "                                          num_train_steps=num_train_steps,\n",
        "                                          num_warmup_steps=num_warmup_steps,\n",
        "                                          optimizer_type='adamw')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAfVlRpVR_hb"
      },
      "source": [
        "classifier_model.compile(optimizer=optimizer,\n",
        "                         loss=loss,\n",
        "                         metrics=metrics)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Hdny2QTSQh1",
        "outputId": "6aa85308-9fbe-432d-e66d-f582b5bc2254"
      },
      "source": [
        "print(f'Training model with {tfhub_handle_encoder}')\n",
        "history = classifier_model.fit(x=train_ds,\n",
        "                               steps_per_epoch=steps_per_epoch,\n",
        "                               validation_data=val_ds,\n",
        "                               validation_steps=validation_steps,\n",
        "                               epochs=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training model with https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n",
            "Epoch 1/10\n",
            "364/364 [==============================] - 59s 162ms/step - loss: 0.0415 - binary_accuracy: 0.9863 - val_loss: 0.1049 - val_binary_accuracy: 0.9745\n",
            "Epoch 2/10\n",
            "364/364 [==============================] - 5s 13ms/step - loss: 0.3060 - binary_accuracy: 0.9286 - val_loss: 0.1050 - val_binary_accuracy: 0.9740\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gy6UVqjVXlia"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}